{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A in MLGS slides - Part 1\n",
    "*some summations to the questions in the slides.*\n",
    "\n",
    "*feel free to revise it if there is somethig wrong.*\n",
    "\n",
    "*@author Riemann Lee*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normalizing Flows\n",
    "### Question-NF1:Change of Variable Formula\n",
    "1. Is $f(z) = 1-z$ a vilid transformation?\n",
    "2. Is $f(z) = 2-3z$ a valid transformation?\n",
    "3. is $\n",
    "    f(z) =\n",
    "    \\left\\{\n",
    "        \\begin{array}\n",
    "            0-z, z \\in [0,1[ \\\\\n",
    "            1-z, z\\in[1,2]\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "    $ a valid transformation?\n",
    "    \n",
    "*** Note here! Must put a \"0\" before a \"minus\" to show \"-\"\n",
    "\n",
    "**Answer-NF1**\n",
    "1. $\\checkmark$: invertibility and differentiability satisfied\n",
    "2. $\\checkmark$: invertibility and differentiability satisfied\n",
    "3. $\\times$: not invertible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-NF2: Forward and Reverse Parametrization\n",
    "1. For which $x$ is it possible to compute $p(x)$ with the forward parametrization?\n",
    "2. Different version:\n",
    "    - Original: Propose a reverse parametrization for exp($-x^n$). Is it possible for any $n$?\n",
    "    \n",
    "    - New: Given the forward transformation $f(z)=exp(z^n)$, compute in closed form the inverse transformation (if possible).\n",
    "\n",
    "\n",
    "3. Propose a reverse parametrization of a sigmoid.\n",
    "\n",
    "**Answer-NF2**\n",
    "1. *To be completed*\n",
    "2. Different Version\n",
    "    - Original: $z = g(x) = exp(-x^n)$, so we have that $x = f(z) = g^{-1}(x) = (-log \\ z)^{\\frac{1}{n}}$.\n",
    "    - New: $x = f(z) = exp(z^n)$, so we have that $z = g(x) = f^{-1}(x) = (log \\ x)^{\\frac{1}{n}}$\n",
    "3. $x = f(z) = \\frac{1}{1+e^{-z}}$, so we have that $z = -log(1 - \\frac{1}{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-NF3: Jacobian Determinant Computation\n",
    "1. Let's assume you get the following Jacobian:\n",
    "$\n",
    "\\left[\n",
    "    \\begin{matrix}\n",
    "        \\frac{\\partial g_1(x_1)}{\\partial x_1} & \\cdots & 0\\\\\n",
    "        \\vdots & \\ddots & \\vdots \\\\\n",
    "        \\frac{\\partial g_D(x_1, \\cdots, x_D)}{\\partial x_1} & \\cdots & 0 \\\\\n",
    "    \\end{matrix}\n",
    "\\right]\n",
    "$\n",
    "How expensive is it to compute the determinant? Can you comment on this in the context of NFs?\n",
    "\n",
    "\n",
    "2. What is the complexity to compute the Jacobian determinant of an arbitary valid transformation?\n",
    "\n",
    "\n",
    "3. What happends for the det(J) when D is high?\n",
    "\n",
    "\n",
    "4. Considering high-dimensional data(i.e. D is high), what type of Jacobian would use?\n",
    "\n",
    "**Answer-NF3**\n",
    "1. $O(0)$ since the last column of the Jacobian is 0\n",
    "2. Full Jacobian can be computed with LU decomposition in $O(D^3)$\n",
    "3. Expensive computational cost\n",
    "4. Better use diagonal or triangle Jacobian for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variational Inference\n",
    "### Questions-VI1: Latent Variable Models\n",
    "1. Assume that we have an LVM, where $p_\\theta(x|z)$ and $p_\\theta(z)$ are tractable(i.e. we can compute them). Can it happen, that we can also compute $p_\\theta(z|x)$ for this model, but cannot compute $p_\\theta(x)$? Why or why not?\n",
    "\n",
    "\n",
    "2. Why is it possible to compute log$p_\\theta(x)$ in a latent variable model, where $z$ can take only finitely many values?\n",
    "\n",
    "**Answer-VI1**\n",
    "1. No; since $p_\\theta(z|x)$, $p_\\theta(x|z)$ and $p_\\theta(z)$ are all computable, we can then use the Bayes formula to compute $p_\\theta(x)$.\n",
    "2. When taliking about normalizing out z, we can also say sampling from z. When z can only take finitely many values, which means the enurmeration is possible, so it is always possible to compute log$p_{\\theta}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions-VI2: Maximization using Lower Bounds\n",
    "1. Slide 57: Why is it necessary for all functions $g \\in \\mathcal{G}$ to be lower bounds on $f$? What happens if some functions in $\\mathcal{G}$ are not lower bounds?\n",
    "\n",
    "\n",
    "2. Slide 57: Can we use a similar approach if we want to approximately <u>minimize</u> some intractable function $f$? What changes need to be done in this case?\n",
    "\n",
    "\n",
    "3. Assume that $p_\\theta(z|x)$ is a distribution on $[0, \\infty)$ (e.g. exponential distibution), and our variational distribution $q(z)$ is a distribution on all of $\\mathcal{R}$(e.g. normal distribution).\n",
    "    - What happens to the ELBO in this case?\n",
    "    - Why is the optimization problem of maximizing the ELBO ill-defined?\n",
    "    - How can we fix this problem?\n",
    "    \n",
    "**Answer-VI2**\n",
    "\n",
    "*See exercise*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-VI3: Optimizing the ELBO\n",
    "1. Which of the following conditions <u>have to</u> be satisfied by a distribution $q(z)$, such that it's <u>possible</u> to use it in variational inference (as described in our recipe on slides 80-81)\n",
    "\n",
    "    a). We can compute the expected value of z in closed form\n",
    "\n",
    "    b). We can compute the entropy of $q(z)$ in closed form\n",
    "\n",
    "    c). We can draw samples from $q(z)$ with reparametrization\n",
    "\n",
    "    d). We can compute the density log $q(z)$ for an atbitary z\n",
    "\n",
    "    e). We can compute log $q(z)$ for a sample z drawn from $q(z)$\n",
    "\n",
    "    f). The distribution can be factorized as $q(z)=\\prod_i q_i(z_i)$\n",
    "\n",
    "\n",
    "2. Think of a probabilistic model with two latent variables $z_1, z_2 \\in \\mathcal{R}$ and an observed variable $x \\in \\mathcal{R}$(i.e. write down $p_\\theta(x|z_1, z_2)$ and $p_\\theta(z_1, z_2)$), where the posterior can be factorized as $p_\\theta(z_1, z_2|x)=p_\\theta(z_1|x) p_\\theta(z_2|x)$.\n",
    "\n",
    "\n",
    "3. Same as question 2, but now the posterior <u>cannot</u> be factorized.\n",
    "\n",
    "**Answer-VI3**\n",
    "1. Note that what we want to do here is\n",
    "$$\\mathop{max}\\limits_{\\theta, \\phi} E_{\\epsilon \\sim b(\\epsilon)} [log p_\\theta(x,z)-log q_\\phi(z)]$$\n",
    "    - a) $\\times$. Optional, not necessary: Nowhere in the formulation to say that we must have to compute the expected value of z in closed form.\n",
    "    - b) $\\times$. Optional, not necessary: Entropy is defined as $H[q_\\phi(z)] = E_{\\epsilon \\sim b(\\epsilon)}[-log q_\\phi(z)]$. But we can anyway use Monte Carlo to compute it. Ofc it's nicer if you can have a closed form, then it will be more accurate.\n",
    "    - c) $\\checkmark$. Yes, necessary: Otherwise we can't use Monte Carlo since the distribution of z now depends on $\\phi$. Ofc it's possible without reparametrization, but it's not the recipe we've used here.\n",
    "    - d) $\\times$ \n",
    "    - e) $\\checkmark$. We just need to compute the density at some point.\n",
    "    - f) $\\times$. Optinal, not necessary. It will be nice in the sense that it will make the calculation much easier. But still we can also do Variational Inference when the distribution doesn't factorize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VAE&GANs\n",
    "### Questions-VAE\n",
    "1. Assume that each data point is represented by a vector $x\\in {1, 2, \\cdots, C}^D$. What distribution would you pick for $p_\\theta(x|z)$? How can we parametrize this distribution with a neural network?\n",
    "2. Assume that each datapoint $x$ is represented by a variable-length sequence of real numbers $x_i \\in \\mathcal{R}^{D_i}$ ($D_i$ might be different for different *i*'s). What NN architecture could we use for the encoder $g_\\lambda$ in this case?\n",
    "3. Slide 94: Assume that we choose to model $p_\\theta(x|z)$ with a normalizing flow. Should we use forward or reverse parametrization? Why?\n",
    "4. Slide 97: Assume that we choose to model $q_\\phi(z)$ with a normalizing flow. Should we use forward or reverse parametrization? Why?\n",
    "5. Slide 106: How can we ensure that the vector $\\sigma$ produced by the encoder $g_\\lambda$ is always positive?\n",
    "\n",
    "**Answer-VAE**\n",
    "1. **To be completed**\n",
    "2. RNN which is special for sequential & temporal data.\n",
    "3. Here we want to compute the possibility for abitary points.\n",
    "4. Forward transformation since we want to draw samples z and then compute $q_{\\phi}(z)$ here. For reverse parametrization, sampling is impossible.\n",
    "5. See exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-GANs\n",
    "1. What can we say about the ration $r^*(x) = p^*(x) / p_\\theta(x)$ when:\n",
    "    \n",
    "    (a) The generator and the discriminator are optimal\n",
    "    \n",
    "    (b) The generator only is optimal\n",
    "    \n",
    "    (c) The discriminator only is optimal\n",
    "\n",
    "\n",
    "2. For a given data $x$, what is the probability for the discriminator to be correct when:\n",
    "\n",
    "    (a) The generator and the discriminator are optimal\n",
    "    \n",
    "    (b) The generator only is optimal\n",
    "    \n",
    "    (c) The discriminator only is optimal\n",
    "    \n",
    "**Answer-GANs**\n",
    "\n",
    "There are two different definitions about the discriminator and generator. When using different definition, one may deduce different answers to this question. First, we can say a generator is optimal when in two respects:\n",
    "    \n",
    "   (a). $p_{\\theta}(x) = p^*(x), \\forall x$\n",
    "   \n",
    "  \n",
    "   (b). $\\mathop{arg\\ min}_\\limits{\\theta} E_{p(z)}[log(1-D_{\\phi}(f_{\\theta}{z}))] = \\theta^*$\n",
    "   \n",
    "   In second case we also need to think about the discriminator\n",
    "   \n",
    "And we talk about the concept of **density ratio:** $D_{\\phi} = \\frac{p^*(x)}{p^*(x)+p_{\\theta}(x)}$ where the term $p^*(x)$ is the true distribution and the term $p_{\\theta}(x)$ is the generated distribution. \n",
    "\n",
    "We can say that this density ratio only depends on generator and has nothing to do with discriminator. W.l.o.g, we assume that here the number of sampels from generator and true distriburion are the same.\n",
    "1. So first think about the first definition. Since the density ratio has nothing to do with disctinimator, then its value is about $\\frac{1}{2}$ as long as the generator are optimized. So in this case both conditions in (a) and (b) will lead the value of $r^*(x)$ to 1, and using the conditions in (c) we cannot tell anything. The reason is that if we don't know how good discriminator is, basically it can be just some function that our generator has optimized, but it doesn't tells us anything about the connection to the true density ratio, so we don't know anything about what happens here. \n",
    "\n",
    "2. For definition 2, since now we need to consider both the generator and discriminator at the same time, so only in condition (a) can we go to the conclusion that the $r^*(x) = 1$. In condition (b) and (c), still we cannot tell anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4&5. Robustness\n",
    "### Question-Robustness1: Adversarial Training\n",
    "1. Given an arbitary classfier *f* for an input domain $\\mathcal{R}^d$ and the perturbation set $\\mathcal{P}_{\\epsilon,p}(x)$ as defines before. Is it possible that every $x \\in \\mathcal{R}^d$ is \"robust\", i.e. no adversarial example exists?\n",
    "2. Will the fast gradient-sign method(FGSM) always find an adversarial example(assuming there exist some in the set of perturbations $\\mathcal{P}_{\\epsilon, \\infty}(x)$)\n",
    "\n",
    "**Answer-Robustness1**\n",
    "1. To put the question differently: Is it possible to have a classifier which is robust at **ANY** $x$? Since the adversarial training just use one worst-case perturbation for training, so we don't have any guarantees of the model's robustness, so it might happen that there are still other adversarial example exists. And in the meanwhile, we are also decreasing the model's accuracy since the best parameters are changed according to this adversarial example. \n",
    "\n",
    "    **Below extract from Piazza**: If the definition set **X** is finite, i.e. for some particular $x$, this can be possible that every $x$ is robust, once they are far enough away from the decision boundary. But if we consider the whole plane, it is not possible, we can always find a point $x$, whose distance to the decision boundary is less than $\\epsilon$.\n",
    "\n",
    "\n",
    "2. No: since the step size towards every direction is 1, this might cause overshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-Robustness2: Convex Relaxation\n",
    "\n",
    "a) The classifier is not robust (w.r.t. the current sample **x**)\n",
    "\n",
    "b) The classifier is robust (w.r.t. the current sample **x**)\n",
    "\n",
    "c) We cannot make a statement\n",
    "\n",
    "1. When the optimal value from our **convex relaxation**, <u>m</u>$_t^*$, is negative, this means that:\n",
    "2. Same question but now the **exact certification**, $m_t^*$, is negative\n",
    "3. Can you think about scenarios where $m_t^*$=<u>m</u>$_t^*$\n",
    "\n",
    "**Answer-Robustness2**\n",
    "1. Answer is c): When the convex relaxation is across the decision boundary, we still have no idea about where the exact perturbation area is.\n",
    "2. Answer is a): There exists at least one adversarial example $\\tilde{x} \\in \\mathcal{P}_{\\epsilon, p}(x)$\n",
    "3. **Abstract from live Q&A-5**: Here the problem means that the lower bound is tight. This can be achieved by lineay classifier, or more generally a convex function, then convex relaxation will just return the same result, but there is also a chance that we get the same result from non-convex function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-Robustness3\n",
    "1. Suppose we define a local variant of Lipschitz constant around a given point $x_0$ as follows:\n",
    "$$\\mathcal{D}_{\\mathcal{Y}}(f(x_0), f(x)) \\leq k_{x_0} \\cdot \\mathcal{D}_{\\mathcal{X}}(x_0, x) \\ \\ \\ \\forall x \\in \\mathcal{X}$$\n",
    "How does the local constant $k_{x_0}$ relate to the global constant $k$ of $f$? Which one would provide better guarantees and why?\n",
    "\n",
    "2. For which class of classifiers does the certificate for the smoothed classifier $g$ equal the certificate for the underlying base classfier $f$ and why?\n",
    "\n",
    "3. Given two classifiers $f_1$ and $f_2$ with Lipschitz constants $k_1$ and $k_2$ with $k_1<k_2$ which one would provide better guarantees? What if we form smoothed classfiers $g_1$ and $g_2$?\n",
    "\n",
    "**Answer-Robustness3**\n",
    "1. **Attention: must distinguish from the upper bound example in the Slide5-74.**\n",
    "\n",
    "    Here since the global Lipschitz constant can contain any of the pairs in the input sequence, so it must be hold that $k \\geq k_i$. \n",
    "    \n",
    "    Below abstract from Piazza: Since only a small fraction of the input space is our interest, and the global constant $k_i$ related to the whole space, the global k could be too large and thus meaningless. With local $k_i$, it is more relevant to our interest and provides better guarantees.\n",
    "\n",
    "\n",
    "2. For the base classifier we have: $f(x) = arg \\mathop{max}_\\limits{c \\in \\mathcal{Y}}\\ F(x)_c$, and for the smooth classifier g we have $g(x)_c = \\mathbb{P}_{\\epsilon}(f(x+\\epsilon)=c)$. Here just the linear classifier can satisfy this property. Assume the worst case on the Gaussian perturbation, and consider a linear classifier that put all the samples to the other class. Then it would't matter whether we just do the smoothing (the Gaussian perturbation here) or just solve without smoothing. It is exactly the original decision boundary, so whatever we certify for, the $g(x)$ will be exactly the same for $f(x)$.\n",
    "\n",
    "\n",
    "3. **Summation of Q&A-5**: It depends on what we mean by better guarantees. If we assume that the accuracy of the same classfier is the same, then it would be clear that $f_1$ is better, because the funtion is smoother compared to $f_2$. Namely, if we perturb the input with $\\triangle$, the change in $f_1$ is smaller than $f_2$.\n",
    "\n",
    "    But if $f_1$, $f_2$ perform the same accuracy given different constraint, it doesn't necessary hold in practice:\n",
    "       -small k ~ more stable by definition, but bad for prediction, the output cannot change too much.\n",
    "       -large k ~ less smooth, less restrict, sacrify stability to be more expressive,  potentially can fit the data better\n",
    "    \n",
    "    Same discussion can also be made about $g_1$, $g_2$. Consider if $g_1$ is higher, then we get larger radius, but can also not predict correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autoregressive & Markov Chains\n",
    "### Question-AR\n",
    "1. What is the mean $E[X_t]$ of the following process:\n",
    "\n",
    "    (a) $X_t = sin(t/10) + \\epsilon_t$ where $\\epsilon_t \\sim  N(0, \\sigma)$ \n",
    "\n",
    "    (b) $X_t = 4 - 0.8*X_{t-1} - 0.1*X_{t-2} + \\epsilon_t$ where $\\epsilon_t \\sim  N(0, \\sigma)$ \n",
    "\n",
    "    (c) $X_t = 4 + X_{t-1} + \\epsilon_t$ where $\\epsilon_t \\sim  N(0, \\sigma)$ and $X_0 \\sim N(0, \\sigma)$\n",
    "\n",
    "\n",
    "2. Does Yule Walker parameter learning assume a stationary process? Why?\n",
    "\n",
    "**Answer-AR**\n",
    "1. See as below\n",
    "    - Not stationary since the mean $E[X_t] = sin(\\frac{t}{10})$ is relavant to time\n",
    "    - Stationary with mean $E[X_t] = \\frac{4}{1.9}$\n",
    "    - Not stationary. We can consider it as an increcemental process, namely adding 4 to $X_t$ at each time step.\n",
    "2. Yes since we have use the formula which is deduced form the stationary process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions-Markov Model\n",
    "1. We assume that $X_t \\in {1,2,3}$. We consider $\\pi = \n",
    "\\left[\n",
    "    \\begin{matrix}\n",
    "          0.0 \\\\ 0.5 \\\\ 0.5\n",
    "    \\end{matrix}\n",
    "\\right]$\n",
    "and $A = \\left[ \n",
    "\\begin{matrix}\n",
    "    0.6 & 0.2 & 0.2 \\\\\n",
    "    0.1 & 0.5 & 0.4 \\\\\n",
    "    0.4 & 0.1 & 0.5\n",
    "\\end{matrix}\n",
    "\\right]$.\n",
    "   - a) What is the possibility to observe the sequence $X^{(1)} = [1, 2, 3]$\n",
    "   - b) What is the possibility to observe the sequence $X^{(1)} = [2, 2, 3]$\n",
    "    \n",
    "2. We assume that $X_t \\in {1, 2, 3}$ and we obseve three sequences:\n",
    "    - $x^{(1)} = [1, 3, 2]$\n",
    "    - $x^{(2)} = [3]$\n",
    "    - $x^{(3)} = [1, 1, 3, 2]$    \n",
    "   What is the MLE of the transition matrix $A \\in \\mathcal{R}^{3 \\times 3}$\n",
    "   \n",
    "**Answer-Markov Model**\n",
    "1. See below\n",
    "    - The possibility is 0 since state 1 never accur in the initial state\n",
    "    - The possibility $p = 0.5 \\times 0.5 \\times 0.4 = 0.1$\n",
    "\n",
    "\n",
    "2. $\\left[ \n",
    "\\begin{matrix}\n",
    "    \\frac{1}{3} & 0 & \\frac{2}{3} \\\\\n",
    "    * & * & * \\\\\n",
    "    0 & 1 & 0\n",
    "\\end{matrix}\n",
    "\\right]$\n",
    "    \n",
    "    We have no idea about the transition probability from state 2 to other state since there is no information at all\n",
    "    \n",
    "    Abstract from Piazza: Here we just asked for the MLE, thus, any (normalized) row for the transitions from 2 will lead to the same likelihood. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
